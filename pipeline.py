# src/pipeline.py


import os  # æ–°å¢ï¼šç”¨äºè®¾ç½®ç¯å¢ƒå˜é‡
from prefect import flow, task
from src.chunker import chunk_text
from src.entity_cache import extract_entities, load_entity_cache, save_entity_cache
from src.translate import babel_translate
os.environ["PREFECT_API_URL"] = "http://127.0.0.1:4200/api"

@task
def chunk_step(text: str):
    return chunk_text(text)


@task
def extract_step(chunks: list[str]):
    entities = set()
    for c in chunks:
        entities.update(extract_entities(c))
    return list(entities)


@task
def update_cache_step(entities: list[str]):
    cache = load_entity_cache()
    for e in entities:
        if e not in cache:
            cache[e] = babel_translate(e, source_lang="en", target_lang="zh")
    save_entity_cache(cache)
    return cache


@task
def translate_step(chunk: str, entity_map: dict[str, str]):
    for src, tgt in entity_map.items():
        chunk = chunk.replace(src, f"<ENT:{src}>")
    translated = babel_translate(chunk, source_lang="en", target_lang="zh")
    for src, tgt in entity_map.items():
        translated = translated.replace(f"<ENT:{src}>", tgt)
    return translated



@flow(name="EnglishToChinese_ConsistentTranslation")
def translation_pipeline(text: str) -> str:
    # å…³é”®ï¼šåœ¨ flow è¿è¡Œå‰å¼ºåˆ¶è®¾ç½® API åœ°å€ï¼ˆé€‚é… 3.4.24 ç‰ˆæœ¬ï¼‰
    
    # 1. åˆ†å—
    print("ğŸ“ æ­£åœ¨åˆ†å—...")
    chunks = chunk_step(text)
    print(f"âœ… æ–‡æœ¬å·²åˆ†ä¸º {len(chunks)} ä¸ªå—")
    
    # 2. æå–å®ä½“
    print("ğŸ” æ­£åœ¨æå–å®ä½“...")
    entity_list = extract_step(chunks)
    print(f"âœ… æ‰¾åˆ° {len(entity_list)} ä¸ªå®ä½“")
    
    # 3. æ›´æ–°ç¼“å­˜
    print("ğŸ’¾ æ­£åœ¨æ›´æ–°å®ä½“ç¼“å­˜...")
    entity_map = update_cache_step(entity_list)
    print(f"âœ… ç¼“å­˜å·²æ›´æ–°ï¼ŒåŒ…å« {len(entity_map)} ä¸ªå®ä½“ç¿»è¯‘")
    
    # 4. ç¿»è¯‘æ¯ä¸ªå—
    print("ğŸŒ æ­£åœ¨ç¿»è¯‘æ–‡æœ¬å—...")
    translated_chunks = []
    for i, chunk in enumerate(chunks, 1):
        print(f"   ç¿»è¯‘å— {i}/{len(chunks)}...")
        translated = translate_step(chunk, entity_map)
        translated_chunks.append(translated)
    
    # 5. åˆå¹¶ç»“æœ
    result = "\n\n".join(translated_chunks)
    print("âœ… ç¿»è¯‘å®Œæˆï¼")
    return result



# from prefect import flow, task
# from src.chunker import chunk_text
# from src.entity_cache import extract_entities, load_entity_cache, save_entity_cache
# from src.translate import babel_translate


# @task
# def chunk_step(text: str):
#     return chunk_text(text)


# @task
# def extract_step(chunks: list[str]):
#     entities = set()
#     for c in chunks:
#         entities.update(extract_entities(c))
#     return list(entities)


# @task
# def update_cache_step(entities: list[str]):
#     cache = load_entity_cache()
#     for e in entities:
#         if e not in cache:
#             cache[e] = babel_translate(e, source_lang="en", target_lang="zh")
#     save_entity_cache(cache)
#     return cache


# @task
# def translate_step(chunk: str, entity_map: dict[str, str]):
#     for src, tgt in entity_map.items():
#         chunk = chunk.replace(src, f"<ENT:{src}>")
#     translated = babel_translate(chunk, source_lang="en", target_lang="zh")
#     for src, tgt in entity_map.items():
#         translated = translated.replace(f"<ENT:{src}>", tgt)
#     return translated


# @flow(name="EnglishToChinese_ConsistentTranslation")
# def translation_pipeline(text: str) -> str:
#     chunks = chunk_step(text)
#     entity_list = extract_step(chunks)
#     entity_map = update_cache_step(entity_list)
#     translated_futures = [translate_step.submit(c, entity_map) for c in chunks]
#     translated_chunks = [f.result() for f in translated_futures]
#     return "\n\n".join(translated_chunks)








# src/pipeline.py

# from prefect import flow, task
# from prefect.settings import PREFECT_API_URL
# from src.chunker import chunk_text
# from src.entity_cache import extract_entities, load_entity_cache, save_entity_cache
# from src.translate import babel_translate

# @task
# def chunk_step(text: str):
#     return chunk_text(text)

# @task
# def extract_step(chunks: list[str]):
#     entities = set()
#     for c in chunks:
#         entities.update(extract_entities(c))
#     return list(entities)

# @task
# def update_cache_step(entities: list[str]):
#     cache = load_entity_cache()
#     for e in entities:
#         if e not in cache:
#             # ç¿»è¯‘å®ä½“ä¸ºä¸­æ–‡
#             cache[e] = babel_translate(e, source_lang="en", target_lang="zh")
#     save_entity_cache(cache)
#     return cache

# @task
# def translate_step(chunk: str, entity_map: dict[str, str]):
#     # æ›¿æ¢å®ä½“ä¸ºæ ‡è®°
#     for src, tgt in entity_map.items():
#         chunk = chunk.replace(src, f"<ENT:{src}>")
#     # è°ƒç”¨çœŸå®ç¿»è¯‘
#     translated = babel_translate(chunk, source_lang="en", target_lang="zh")
#     # æ¢å¤å®ä½“ç¿»è¯‘
#     for src, tgt in entity_map.items():
#         translated = translated.replace(f"<ENT:{src}>", tgt)
#     return translated

# @flow(name="EnglishToChinese_ConsistentTranslation")
# def translation_pipeline(text: str) -> str:
#     chunks = chunk_step(text)
#     entity_list = extract_step(chunks)
#     entity_map = update_cache_step(entity_list)
#     # å¹¶è¡Œç¿»è¯‘æ¯ä¸€ä¸ª chunk
#     translated_futures = [translate_step.submit(c, entity_map) for c in chunks]
#     translated_chunks = [f.result() for f in translated_futures]
#     result = "\n\n".join(translated_chunks)
#     return result
